<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Conversation Mediator (GPT-4o)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', 'Noto Sans JP', sans-serif;
            touch-action: manipulation; /* Disable double-tap to zoom on mobile */
        }
        .pulse {
            box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.7);
            animation: pulse-blue 1.5s infinite;
        }
        @keyframes pulse-blue {
            0% { box-shadow: 0 0 0 0 rgba(59, 130, 246, 0.7); }
            70% { box-shadow: 0 0 0 20px rgba(59, 130, 246, 0); }
            100% { box-shadow: 0 0 0 0 rgba(59, 130, 246, 0); }
        }
        .talk-button {
            transition: transform 0.1s ease-in-out, box-shadow 0.2s ease;
        }
        .talk-button:active {
            transform: scale(0.95);
            box-shadow: 0 2px 10px rgba(0,0,0,0.2);
        }
        #conversation-log {
            scroll-behavior: smooth;
        }
        .message-bubble {
            max-width: 85%;
        }
        .message-bubble.user-a {
            background-color: #e0f2fe; /* light blue */
            align-self: flex-start;
        }
        .message-bubble.user-b {
            background-color: #e0f2f1; /* light teal */
            align-self: flex-end;
        }
        .message-bubble.mediator {
            background-color: #f3f4f6; /* light gray */
        }
    </style>
</head>
<body class="bg-gray-100 flex flex-col h-screen antialiased">

    <!-- Header -->
    <header class="bg-white shadow-md p-4 flex justify-between items-center z-10">
        <div class="flex items-center space-x-3">
            <i class="fas fa-comments text-2xl text-blue-500"></i>
            <h1 class="text-xl font-bold text-gray-800">AI会話支援アプリ</h1>
        </div>
        <button id="settings-button" class="text-gray-600 hover:text-blue-500 transition">
            <i class="fas fa-cog text-2xl"></i>
        </button>
    </header>

    <!-- Main Content -->
    <main class="flex-grow flex flex-col p-4 overflow-hidden">
        <!-- Conversation Log -->
        <div id="conversation-log" class="flex-grow bg-white rounded-lg shadow-inner p-4 mb-4 overflow-y-auto flex flex-col space-y-4">
             <!-- Initial message will be added by JavaScript -->
        </div>

        <!-- Status Display -->
        <div id="status-display" class="text-center text-gray-600 mb-4 h-6 transition-opacity duration-300"></div>

        <!-- User Controls -->
        <div class="flex justify-center items-center mb-4 bg-white p-4 rounded-lg shadow space-x-4">
            <!-- User A Language -->
            <div class="flex-1">
                <label for="user-a-lang" class="block text-center text-sm font-medium text-gray-700 mb-1"></label>
                <select id="user-a-lang" class="w-full p-2 border rounded-md text-center">
                    <option value="ja" selected>日本語 (Japanese)</option>
                    <option value="en">英語 (English)</option>
                    <option value="zh">中国語 (Chinese)</option>
                    <option value="ko">韓国語 (Korean)</option>
                    <option value="es">スペイン語 (Spanish)</option>
                </select>
            </div>

            <div class="self-center pt-6">
                <i class="fas fa-exchange-alt text-gray-400 text-2xl"></i>
            </div>

            <!-- User B Language -->
            <div class="flex-1">
                <label for="user-b-lang" class="block text-center text-sm font-medium text-gray-700 mb-1"></label>
                <select id="user-b-lang" class="w-full p-2 border rounded-md text-center">
                    <option value="zh" selected>中国語 (Chinese)</option>
                    <option value="en">英語 (English)</option>
                    <option value="ja">日本語 (Japanese)</option>
                    <option value="ko">韓国語 (Korean)</option>
                    <option value="es">スペイン語 (Spanish)</option>
                </select>
            </div>
        </div>


        <!-- Single Talk Button -->
        <div class="flex justify-center mt-4">
            <button id="talk-button" class="talk-button w-28 h-28 rounded-full bg-blue-500 text-white flex items-center justify-center shadow-lg">
                <i class="fas fa-microphone text-5xl"></i>
            </button>
        </div>
    </main>

    <!-- Settings Modal -->
    <div id="settings-modal" class="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center p-4 hidden z-50">
        <div class="bg-white rounded-lg shadow-xl p-6 w-full max-w-md">
            <div class="flex justify-between items-center mb-4">
                <h2 class="text-2xl font-bold">設定</h2>
                <button id="close-modal-button" class="text-gray-500 hover:text-gray-800">&times;</button>
            </div>
            <div class="space-y-4">
                <div>
                    <label for="api-key-input" class="block text-sm font-medium text-gray-700">OpenAI API Key</label>
                    <input type="password" id="api-key-input" class="mt-1 block w-full px-3 py-2 bg-white border border-gray-300 rounded-md shadow-sm placeholder-gray-400 focus:outline-none focus:ring-blue-500 focus:border-blue-500">
                    <p class="mt-1 text-xs text-gray-500">APIキーはブラウザ内にのみ保存されます。</p>
                </div>
                <div>
                    <label for="scenario-select" class="block text-sm font-medium text-gray-700">会話シナリオ</label>
                    <select id="scenario-select" class="mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-blue-500 focus:border-blue-500 sm:text-sm rounded-md">
                        <option value="taxi" selected>タクシー (運転手と乗客)</option>
                        <option value="store">コンビニ (店員と客)</option>
                        <option value="general">一般会話</option>
                    </select>
                </div>
                <button id="save-settings-button" class="w-full bg-blue-500 text-white py-2 px-4 rounded-md hover:bg-blue-600 focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-blue-500">
                    保存
                </button>
            </div>
        </div>
    </div>

    <script type="module">
        // DOM Elements
        const settingsButton = document.getElementById('settings-button');
        const settingsModal = document.getElementById('settings-modal');
        const closeModalButton = document.getElementById('close-modal-button');
        const saveSettingsButton = document.getElementById('save-settings-button');
        const apiKeyInput = document.getElementById('api-key-input');
        const scenarioSelect = document.getElementById('scenario-select');
        const talkButton = document.getElementById('talk-button');
        const userALang = document.getElementById('user-a-lang');
        const userBLang = document.getElementById('user-b-lang');
        const conversationLog = document.getElementById('conversation-log');
        const statusDisplay = document.getElementById('status-display');

        // App State
        let apiKey = localStorage.getItem('openai_api_key') || '';
        let mediaRecorder;
        let audioChunks = [];
        let conversationHistory = [];
        let isRecording = false;
        let activeUser = null; 

        const TRANSLATIONS = {
            'ja': {
                'User A': 'ユーザーA', 'User B': 'ユーザーB', 'Mediator': 'メディエーター',
                'User A\'s Language': 'ユーザーAの言語', 'User B\'s Language': 'ユーザーBの言語',
                'Welcome': 'こんにちは！設定<i class="fas fa-cog"></i>からAPIキーとシナリオを設定し、マイクボタンを押して会話を始めてください。'
            },
            'en': {
                'User A': 'User A', 'User B': 'User B', 'Mediator': 'Mediator',
                'User A\'s Language': 'User A\'s Language', 'User B\'s Language': 'User B\'s Language',
                'Welcome': 'Hello! Set your API key and scenario in Settings <i class="fas fa-cog"></i>, then press the mic button to start.'
            },
            'zh': {
                'User A': '用户A', 'User B': '用户B', 'Mediator': '调解员',
                'User A\'s Language': '用户A的语言', 'User B\'s Language': '用户B的语言',
                'Welcome': '您好！请在设置<i class="fas fa-cog"></i>中设定您的API密钥和场景，然后按下麦克风按钮开始对话。'
            },
            'ko': {
                'User A': '사용자 A', 'User B': '사용자 B', 'Mediator': '중재자',
                'User A\'s Language': '사용자 A의 언어', 'User B\'s Language': '사용자 B의 언어',
                'Welcome': '안녕하세요! 설정<i class="fas fa-cog"></i>에서 API 키와 시나리오를 설정한 후, 마이크 버튼을 눌러 대화를 시작하세요.'
            },
            'es': {
                'User A': 'Usuario A', 'User B': 'Usuario B', 'Mediator': 'Mediador',
                'User A\'s Language': 'Idioma del Usuario A', 'User B\'s Language': 'Idioma del Usuario B',
                'Welcome': '¡Hola! Configura tu clave de API y el escenario en los ajustes <i class="fas fa-cog"></i>, y luego presiona el botón del micrófono para comenzar.'
            }
        };

        const SCENARIO_PROMPTS = {
            taxi: `あなたは、プロのAI会話メディエーターです。タクシーの運転手と乗客の会話を円滑に進める役割を担っています。単語を直訳するのではなく、双方の発言の意図と目的を深く理解してください。そして、相手が次に何をすべきか明確にわかるように、情報を整理し、丁寧かつ具体的な言葉で伝えてください。例えば、乗客が曖昧な場所を言及した場合（例：「大きな提灯があるお寺」）、それを具体的な場所（例：「浅草の雷門ですね」）として補完し、運転手に行動を提案（例：「では、浅草の雷門へ向かいますね」）してください。会話のゴールは、乗客が目的地に安全かつ快適に到着し、運転手がそれを正確にサポートすることです。`,
            store: `あなたは、プロのAI会話メディエーターです。コンビニの店員とお客様の会話を円滑に進める役割を担っています。単語を直訳するのではなく、双方の発言の意図と目的を深く理解してください。そして、相手が次に何をすべきか明確にわかるように、情報を整理し、丁寧かつ具体的な言葉で伝えてください。例えば、お客様が商品について質問した場合、店員が答えやすいように質問を整理したり、店員からの提案（例：「温めますか？」）をお客様が理解しやすいように伝えたりします。会話のゴールは、お客様が必要な商品をスムーズに購入でき、店員が効率的に接客を完了させることです。`,
            general: `あなたは、プロのAI会話メディエーターです。異なる言語を話す二人の会話を円滑に進める役割を担っています。単語を直訳するのではなく、双方の発言の意図と目的を深く理解してください。そして、相手が次に何をすべきか明確にわかるように、情報を整理し、丁寧かつ具体的な言葉で伝えてください。文化的な背景の違いを考慮し、誤解が生じないように配慮してください。会話のゴールは、二人がストレスなく意思疎通を図り、良好な関係を築くことです。`
        };

        // --- UI Functions ---

        const showModal = () => settingsModal.classList.remove('hidden');
        const hideModal = () => settingsModal.classList.add('hidden');

        const updateStatus = (text, isLoading = false) => {
            statusDisplay.innerHTML = text ? `${text} ${isLoading ? '<i class="fas fa-spinner fa-spin ml-2"></i>' : ''}` : '';
        };

        const getBilingualLabel = (key) => {
            const langA = userALang.value;
            const langB = userBLang.value;
            const textA = TRANSLATIONS[langA]?.[key] || key;
            const textB = TRANSLATIONS[langB]?.[key] || key;
            return textA === textB ? textA : `${textA} / ${textB}`;
        };
        
        const updateUILabels = () => {
            document.querySelector('label[for="user-a-lang"]').innerHTML = getBilingualLabel("User A's Language");
            document.querySelector('label[for="user-b-lang"]').innerHTML = getBilingualLabel("User B's Language");
        };

        const displayInitialMessage = () => {
            const langA = userALang.value;
            const langB = userBLang.value;
            const welcomeMsgA = TRANSLATIONS[langA]?.['Welcome'] || TRANSLATIONS['en']['Welcome'];
            const welcomeMsgB = TRANSLATIONS[langB]?.['Welcome'] || TRANSLATIONS['en']['Welcome'];
            const finalWelcomeMsg = welcomeMsgA === welcomeMsgB ? welcomeMsgA : `${welcomeMsgA}<hr class="my-2 border-gray-300/50">${welcomeMsgB}`;
            
            conversationLog.innerHTML = ''; // Clear previous messages
            const messageDiv = document.createElement('div');
            messageDiv.className = `message-bubble user-a mediator rounded-lg p-3`;
            messageDiv.innerHTML = `<p class="text-sm font-semibold text-gray-500">${getBilingualLabel('Mediator')}</p><p class="text-gray-800">${finalWelcomeMsg}</p>`;
            conversationLog.appendChild(messageDiv);
        };

        const addMessageToLog = (speakerKey, text, translatedText = null, userClass = '') => {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message-bubble rounded-lg p-3 ${userClass}`;
            
            const speakerLabel = getBilingualLabel(speakerKey);
            let content = `<p class="text-sm font-semibold text-gray-500">${speakerLabel}</p><p class="text-gray-800">${text}</p>`;
            if(translatedText){
                content += `<hr class="my-2 border-gray-300/50"><p class="text-sm text-gray-600">${translatedText}</p>`;
            }
            messageDiv.innerHTML = content;
            conversationLog.appendChild(messageDiv);
            conversationLog.scrollTop = conversationLog.scrollHeight;
        };

        // --- Core Logic ---

        const startRecording = async () => {
            if (isRecording) return;
            if (!apiKey) {
                alert('APIキーが設定されていません。設定画面からキーを入力してください。');
                showModal();
                return;
            }

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                isRecording = true;
                audioChunks = [];
                mediaRecorder = new MediaRecorder(stream);
                mediaRecorder.ondataavailable = event => audioChunks.push(event.data);
                mediaRecorder.onstop = processAudio;
                mediaRecorder.start();
                
                talkButton.classList.add('pulse', 'scale-110');
                updateStatus('話してください...');
            } catch (error) {
                console.error('Error starting recording:', error);
                alert('マイクへのアクセス許可が必要です。');
            }
        };

        const stopRecording = () => {
            if (!isRecording || !mediaRecorder) return;
            mediaRecorder.stop();
            isRecording = false;

            talkButton.classList.remove('pulse', 'scale-110');
            updateStatus('音声を処理中...', true);
        };

        const processAudio = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            
            try {
                const transcription = await transcribeAudio(audioBlob);
                if (!transcription || transcription.trim() === '') {
                    updateStatus('音声が聞き取れませんでした。');
                    setTimeout(() => updateStatus(''), 2000);
                    return;
                }
                
                const identifiedUser = await identifySpeaker(transcription);
                activeUser = identifiedUser; 

                const fromLang = activeUser === 'A' ? userALang.selectedOptions[0].text : userBLang.selectedOptions[0].text;
                const toLang = activeUser === 'A' ? userBLang.selectedOptions[0].text : userALang.selectedOptions[0].text;
                const speakerKey = activeUser === 'A' ? "User A" : "User B";

                const translatedUtterance = await translateText(transcription, toLang);

                const mediatedResult = await getMediatedResponse(transcription, fromLang, toLang, speakerKey);
                
                const originalSpeakerClass = activeUser === 'A' ? 'user-a' : 'user-b';
                addMessageToLog(speakerKey, transcription, translatedUtterance, originalSpeakerClass);

                const audioUrl = await textToSpeech(mediatedResult.message);

                let alignmentClass;
                if (mediatedResult.target === 'speaker') {
                    alignmentClass = activeUser === 'A' ? 'user-a' : 'user-b';
                } else { 
                    alignmentClass = activeUser === 'A' ? 'user-b' : 'user-a';
                }
                addMessageToLog("Mediator", mediatedResult.message, null, `${alignmentClass} mediator`);

                const audio = new Audio(audioUrl);
                audio.play();
                updateStatus('');

            } catch (error) {
                console.error('Error processing audio pipeline:', error);
                updateStatus(`エラーが発生しました: ${error.message}`);
                setTimeout(() => updateStatus(''), 5000);
            }
        };

        // --- OpenAI API Calls ---

        async function apiCall(endpoint, options) {
            const response = await fetch(`https://api.openai.com/v1/${endpoint}`, {
                ...options,
                headers: {
                    ...options.headers,
                    'Authorization': `Bearer ${apiKey}`
                }
            });
            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(errorData.error.message || `API request failed with status ${response.status}`);
            }
            return response;
        }

        async function transcribeAudio(audioBlob) {
            updateStatus('音声をテキストに変換中...', true);
            const formData = new FormData();
            formData.append('file', audioBlob, 'recording.webm');
            formData.append('model', 'whisper-1');

            const response = await apiCall('audio/transcriptions', {
                method: 'POST',
                body: formData
            });

            const data = await response.json();
            return data.text;
        }
        
        async function identifySpeaker(text) {
            updateStatus('話者を識別中...', true);
            const langA = { code: userALang.value, name: userALang.options[userALang.selectedIndex].text };
            const langB = { code: userBLang.value, name: userBLang.options[userBLang.selectedIndex].text };

            if (langA.code === langB.code) {
                console.warn("Both users have the same language. Defaulting to User A.");
                return 'A';
            }

            const prompt = `The following text is a transcription of speech. The speaker's native language is either ${langA.name} or ${langB.name}. Please identify which language the text is primarily written in. Respond with ONLY the language code, for example '${langA.code}' or '${langB.code}'. Do not add any other text or explanation.\n\nText: "${text}"`;

            try {
                const response = await apiCall('chat/completions', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        model: 'gpt-4o',
                        messages: [{ role: "system", content: "You are a language identification expert." }, { role: "user", content: prompt }],
                        temperature: 0,
                        max_tokens: 5
                    })
                });

                const data = await response.json();
                const detectedLangCode = data.choices[0].message.content.trim().toLowerCase();

                if (detectedLangCode.includes(langA.code)) {
                    return 'A';
                } else if (detectedLangCode.includes(langB.code)) {
                    return 'B';
                } else {
                    console.warn(`Language identification returned an unexpected value: ${detectedLangCode}. Defaulting to User A.`);
                    return 'A'; 
                }
            } catch (error) {
                console.error('Error during language identification:', error);
                return 'A'; 
            }
        }

        async function translateText(text, targetLang) {
            updateStatus('原文を翻訳中...', true);
            const prompt = `Translate the following text into ${targetLang}. Respond with ONLY the translated text, without any additional text, formatting, or explanations.`;

            try {
                const response = await apiCall('chat/completions', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        model: 'gpt-4o',
                        messages: [{ role: "user", content: `${prompt}\n\nText: "${text}"` }],
                        temperature: 0,
                    })
                });
                const data = await response.json();
                return data.choices[0].message.content.trim();
            } catch (error) {
                console.error('Error during translation:', error);
                return "[翻訳エラー]";
            }
        }


        async function getMediatedResponse(text, fromLang, toLang, speakerKey) {
            updateStatus('AIが応答を生成中...', true);
            const scenario = scenarioSelect.value;
            const speakerNameA = TRANSLATIONS[userALang.value]['User A'];
            const speakerNameB = TRANSLATIONS[userBLang.value]['User B'];

            const systemPrompt = `${SCENARIO_PROMPTS[scenario]} ${speakerNameA}は「${userALang.selectedOptions[0].text}」を、${speakerNameB}は「${userBLang.selectedOptions[0].text}」を話します。
あなたの応答は、必ず以下のJSON形式で返してください。
{
  "target": "listener" | "speaker",
  "message": "ここに相手に伝えるメッセージや、話者に問いかける質問を記述します"
}
- "target": あなたの応答が、会話の相手（聞いていた側）に伝えるべきメッセージの場合は "listener" を指定してください。あなたの応答が、今発言した本人（話していた側）に対して、意図を明確にするための確認や質問の場合は "speaker" を指定してください。
- "message": targetが "listener" の場合、メッセージは相手の言語（${toLang}）で生成してください。targetが "speaker" の場合、メッセージは発言者本人の言語（${fromLang}）で生成してください。`;

            if (conversationHistory.length > 10) {
                conversationHistory = conversationHistory.slice(-10);
            }
            
            const speakerName = (speakerKey === 'User A') ? speakerNameA : speakerNameB;
            conversationHistory.push({ role: "user", content: `[${speakerName} (${fromLang})の発言]: ${text}` });

            const response = await apiCall('chat/completions', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    model: 'gpt-4o',
                    response_format: { type: "json_object" }, 
                    messages: [
                        { role: "system", content: systemPrompt },
                        ...conversationHistory
                    ],
                    temperature: 0.5,
                })
            });

            const data = await response.json();
            const mediatedContent = JSON.parse(data.choices[0].message.content);
            conversationHistory.push({ role: "assistant", content: data.choices[0].message.content }); 
            return mediatedContent;
        }

        async function textToSpeech(text) {
            updateStatus('音声を生成中...', true);
            const response = await apiCall('audio/speech', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    model: 'tts-1',
                    input: text,
                    voice: 'nova'
                })
            });
            
            const audioBlob = await response.blob();
            return URL.createObjectURL(audioBlob);
        }

        // --- Event Listeners ---

        settingsButton.addEventListener('click', showModal);
        closeModalButton.addEventListener('click', hideModal);

        const resetConversation = () => {
            conversationHistory = [];
            updateUILabels();
            displayInitialMessage();
        };

        saveSettingsButton.addEventListener('click', () => {
            const newApiKey = apiKeyInput.value.trim();
            if (newApiKey) {
                apiKey = newApiKey;
                localStorage.setItem('openai_api_key', apiKey);
                alert('設定を保存しました。');
                hideModal();
                resetConversation();
            } else {
                alert('APIキーを入力してください。');
            }
        });
        
        userALang.addEventListener('change', resetConversation);
        userBLang.addEventListener('change', resetConversation);
        
        const handlePress = (e) => {
            e.preventDefault();
            startRecording();
        };
        const handleRelease = (e) => {
            e.preventDefault();
            stopRecording();
        };

        talkButton.addEventListener('mousedown', handlePress);
        talkButton.addEventListener('mouseup', handleRelease);
        talkButton.addEventListener('mouseleave', () => { if (isRecording) stopRecording(); });
        talkButton.addEventListener('touchstart', handlePress);
        talkButton.addEventListener('touchend', handleRelease);

        // --- Initialization ---

        function initialize() {
            apiKeyInput.value = apiKey;
            resetConversation();
            if (!apiKey) {
                setTimeout(showModal, 500);
            }
        }

        initialize();
    </script>
</body>
</html>

